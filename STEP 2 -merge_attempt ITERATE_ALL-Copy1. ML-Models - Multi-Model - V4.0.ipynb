{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# this is runs model variations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "### > save_info function is overwriting itself which is pointless...\n",
    "### ~~>change the scoreing method insted of weighted avg... its weight avg - anti avg...~~\n",
    "### ~~> i want targs at the top so i can quickly go through differnt verisons of shit- but its pointless until i fix the true positive thing~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-27e9bf078abd>, line 147)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-27e9bf078abd>\"\u001b[0;36m, line \u001b[0;32m147\u001b[0m\n\u001b[0;31m    jplt = #sns.jointplot(y_test,pred)\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "clean_initiate= datetime.now()\n",
    "\n",
    "\n",
    "info = {}\n",
    "from datetime import datetime\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import matplotlib.pyplot as plt\n",
    "#import seaborn as #sns\n",
    "#import cufflinks as cf\n",
    "#cf.go_offline(connected=False)\n",
    "stamp = str(datetime.now())\n",
    "info['stamp'] = stamp\n",
    "import os\n",
    "path = 'clean_data/'\n",
    "info['path'] = path\n",
    "sheets = os.listdir(path)\n",
    "pd.DataFrame(sheets)\n",
    "\n",
    "#features in fdf\n",
    "sheet = path+sheets[2] \n",
    "fdf = pd.read_csv(sheet)\n",
    "fdf = fdf.rename(columns={'time':'date'})\n",
    "\n",
    "#TARGETS GO IN DF\n",
    "df = pd.read_csv(path+sheets[0])\n",
    "df = df.rename(columns={'time':'date'})\n",
    "#makeing copys in case fuck-ups\n",
    "ddf = df.copy()\n",
    "dfdf = fdf.copy()\n",
    "df.head()\n",
    "\n",
    "# REMOVING THE FUCKING INDEXES...\n",
    "\n",
    "#bullshit = ['Unnamed: 0','index']\n",
    "#fdf = fdf.drop(bullshit,axis=1)\n",
    "#df = df.drop(bullshit,axis=1)\n",
    "fdf.head()\n",
    "\n",
    "df.head()\n",
    "\n",
    "# targets\n",
    "\n",
    "#CREATING LIST OF TARGETS!\n",
    "targs = []\n",
    "for i in df.columns:\n",
    "    if '!' in i:\n",
    "        targs.append(i)\n",
    "tardf = pd.DataFrame(targs,columns=['targets'])\n",
    "tardf\n",
    "\n",
    "target  = targs[22]\n",
    "dtarget = targs[23]\n",
    "info['target'] = df[target]\n",
    "print('target...............:     ',target, '\\nanti-target..........:',dtarget)\n",
    "print('rows:',len(df))\n",
    "\n",
    "# split here and load in sheets..\n",
    "\n",
    "#SPLIT BASED ON PERCENT\n",
    "split_per = 0.3 * len(df)\n",
    "split     = len(df) - int(split_per)\n",
    "\n",
    "#MANUAL SPLIT\n",
    "#split = 1000\n",
    "split\n",
    "\n",
    "print('lenth:',len(fdf),len(df))\n",
    "\n",
    "print(split)\n",
    "\n",
    "fe_first = fdf[:split]\n",
    "df_first  = df[:split]\n",
    "\n",
    "#second \n",
    "fe_second = fdf[split:]\n",
    "df_second = df[split:]\n",
    "#goingto have to do curent differently, by saving the columns this will be easy\n",
    "#current= fdf[:-100]\n",
    "\n",
    "#  functions\n",
    "\n",
    "from tqdm import trange\n",
    "def sheet_n_sec():\n",
    "    #this saves the sheet and name to the refrence dictionary 'info'\n",
    "    info['sheet'] = sheet\n",
    "    info['sec'] = sheet.replace('.csv','')\n",
    "    \n",
    "def save_timeframe():\n",
    "    #saves the timeframe to the refrence dictionary 'info' \n",
    "    tfr = str(pd.Timedelta(df.index[0])-pd.Timedelta(df.index[1]))\n",
    "    tfr = tfr.split('.')[0]\n",
    "    info['time_frame'] = tfr    \n",
    "\n",
    "    \n",
    "def save_start_stop():\n",
    "    #this saves the start and stop dates to the dic 'info'\n",
    "    start = str(df['Date'][0])\n",
    "    end = str(df['Date'][-1:])\n",
    "    info['start'] = start\n",
    "    info['end'] = end    \n",
    "\n",
    "def df_split(df,split_pct_fmEnd=.2):\n",
    "    #splits a dataframe into 'first'&'second' based on a given percentage\n",
    "    split = int(math.ceil(split_pct_fmEnd*len(df)))\n",
    "    split = int(len(df) - forcast_out*split_pct_fmEnd)\n",
    "    print('df_len',len(df))\n",
    "    print('split is',split)\n",
    "    first = df[:split]\n",
    "    second = df[split:]\n",
    "    print('first_ends:',first.index[-1])\n",
    "    print('second_starts:',second.index[0])\n",
    "    return first, second\n",
    "\n",
    "def ttsplit(x,y):\n",
    "    #train_test_split simply saves some trouble, of typeing\n",
    "    x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.33,random_state=42)\n",
    "    return x_train,x_test,y_train,y_test\n",
    "\n",
    "'''MACHINE LEARNING MODELS'''\n",
    "#model dictionary save attribtes and results of each model to be saved later\n",
    "modeldic = {}\n",
    "def lin_reg_fit(x,y,name=' ',notes=''):\n",
    "    # i didnt add any dtargs to the metrics....i you think of any, DO IT DO IT DO IT!!!!!!!\n",
    "    '''#ouputs the model, model_id, predictions & coef_df in a list, while saving all parmas to 'modeldic'\n",
    "    runs a linear model and save the paramaters, outputs,\n",
    "    the model,model_id, prediction, and a coeficiant dataframe '''\n",
    "    indic = {}\n",
    "    mstamp = str(datetime.now())\n",
    "    mtype = 'LinearRegression'\n",
    "    sn = mstamp.split('.')[1]\n",
    "    modelid = mtype+sn\n",
    "    #adding paramaters\n",
    "    indic['model_id'] = modelid\n",
    "    indic['model_name'] = ltarget+modelid #this is striclty beinf used for nameing\n",
    "    indic['model_notes'] = 'fit_intercept=False' #notes\n",
    "    indic['stamp'] = mstamp\n",
    "    indic['model_type'] = mtype\n",
    "    indic['features'] = str(x.columns)\n",
    "    indic['target']   = ltarget\n",
    "    #setting up model\n",
    "    lm = LinearRegression(fit_intercept=False)\n",
    "    lm.fit(x_train,y_train)\n",
    "    pred = lm.predict(x_test)\n",
    "    jplt = #sns.jointplot(y_test,pred)\n",
    "    coef = lm.coef_ \n",
    "    \n",
    "    codf = pd.DataFrame(coef,x.columns,columns=['coefs'])\n",
    "    #this would be if you wanted to rank them ....\n",
    "    #for i in trange(0,len(codf)):\n",
    "    #    if codf['coefs'][i] < 0:\n",
    "    #        codf['coefs'][i] = codf['coefs'][i] * -1\n",
    "    codf = codf.T\n",
    "    \n",
    "    codf#.iplot(kind='bar',theme='#solar')\n",
    "    r2 = r2_score(y_test,pred)\n",
    "    mae = mean_absolute_error(y_test,pred)\n",
    "    indic['r2_score'] = r2\n",
    "    indic['MAE'] = mae\n",
    "    print('r2 score',r2)\n",
    "    print('mean_absolute_er',mae)\n",
    "    codf\n",
    "    indic['coefs'] = codf.T['coefs'].values\n",
    "    modeldic[modelid] = indic\n",
    "    return [lm, modelid, pred,codf]#,codf.T#.iplot(kind='bar',theme='#solar')\n",
    "def log_reg_fit(x,y,dy,name=' ',notes=''):\n",
    "    #ouputs the model, model_id, predictions & coef_df in a list, while saving all parmas to 'modeldic'\n",
    "    #runs a Logistic model and save the paramaters, outputs,\n",
    "    #the model,model_id, prediction, and a coeficiant dataframe \n",
    "    \n",
    "    indic = {}\n",
    "    mstamp = str(datetime.now())\n",
    "    '''model'''\n",
    "    mtype = 'LogisticRegression'\n",
    "    sn = mstamp.split('.')[1]\n",
    "    modelid = mtype+sn\n",
    "    #adding paramaters\n",
    "    indic['model_id'] = modelid\n",
    "    indic['model_name'] = target+modelid #this is striclty beinf used for nameing\n",
    "    indic['model_notes'] = 'max_iter is on 4000'#notes\n",
    "    indic['stamp'] = mstamp\n",
    "    indic['model_type'] = mtype\n",
    "    indic['features'] = str(x.columns)\n",
    "    #setting up model\n",
    "    '''object name'''\n",
    "    lr = LogisticRegression(max_iter=4000)\n",
    "    lr.fit(x_train,y_train)\n",
    "    pred = lr.predict(x_test)\n",
    "    #dont think this will work on \n",
    "    coef = lr.coef_ \n",
    "    \n",
    "    codf = pd.DataFrame(coef,columns=[x.columns])#,x.columns)#,columns=['coefs'])\n",
    "    #this would be if you wanted to rank them ....\n",
    "    #for i in trange(0,len(codf)):\n",
    "    #    if codf['coefs'][i] < 0:\n",
    "    #        codf['coefs'][i] = codf['coefs'][i] * -1\n",
    "    #codf = codf.T\n",
    "    \n",
    "    codf#.iplot(kind='bar',theme='#solar')\n",
    "    \n",
    "    #metrics\n",
    "    clr = classification_report(y_test,pred)\n",
    "    dclr= classification_report(dy_test,pred)\n",
    "    print('~~~~~~~~~~~~~~~~~~~~~~~HITTNG THE TARGET~~~~~~~~~~~~~~~~~~~~~~~~~\\n',clr)\n",
    "    print('..............................vs................................')\n",
    "    print('~~~~~~~~~~~~~~~~~~~~~~~ THE ANTI-TARGET~~~~~~~~~~~~~~~~~~~~~~~~~\\n',dclr)\n",
    "    comx = confusion_matrix(y_test,pred)\n",
    "    print(\"~~~~~~~~~~~~~~~~~~~~~~[CONFUSION MATRIX:]~~~~~~~~~~~~~~~~~~~~~~~\" )\n",
    "    print(\"                 ......///\",comx[0], \"\\\\\\.........\" )\n",
    "    print(\"                 ...../// \",comx[1], \" \\\\\\.........\" )\n",
    "    #classification report\n",
    "    clr = classification_report(y_test,pred,output_dict=True)\n",
    "    clrdf = pd.DataFrame(clr)\n",
    "    indic['true_positive']=clr['True']['precision']\n",
    "    indic['true_negitive']=clr['False']['precision']\n",
    "    indic['weighted avg'] =clr['weighted avg']['precision']\n",
    "    indic['f1_score']     =clr['weighted avg']['f1-score']\n",
    "    codf\n",
    "    modeldic[modelid] = indic\n",
    "    return [lr, modelid, pred,clrdf,codf] #,codf.T#.iplot(kind='bar',theme='#solar')\n",
    "\n",
    "def tree_fit(x,y,dy,name=' ',notes=''):\n",
    "    indic = {}\n",
    "    mstamp = str(datetime.now())\n",
    "    '''model'''\n",
    "    mtype = 'Tree'\n",
    "    sn = mstamp.split('.')[1]\n",
    "    modelid = mtype+sn\n",
    "    #adding paramaters\n",
    "    indic['model_id'] = modelid\n",
    "    indic['model_name'] = target+modelid #this is striclty beinf used for nameing\n",
    "    indic['model_notes'] = 'default-tree '#notes\n",
    "    indic['stamp'] = mstamp\n",
    "    indic['model_type'] = mtype\n",
    "    indic['features'] = str(x.columns)\n",
    "    indic['target']   = target\n",
    "    #setting up model\n",
    "    '''object name'''\n",
    "    tree = DecisionTreeClassifier('entropy')\n",
    "    tree.fit(x_train,y_train)\n",
    "    pred = tree.predict(x_test)\n",
    "    #metrics\n",
    "    clr = classification_report(y_test,pred)\n",
    "    dclr= classification_report(dy_test,pred)\n",
    "    print('~~~~~~~~~~~~~~~~~~~~~~~HITTNG THE TARGET~~~~~~~~~~~~~~~~~~~~~~~~~\\n',clr)\n",
    "    print('..............................vs................................')\n",
    "    print('~~~~~~~~~~~~~~~~~~~~~~~ THE ANTI-TARGET~~~~~~~~~~~~~~~~~~~~~~~~~\\n',dclr)\n",
    "    comx = confusion_matrix(y_test,pred)\n",
    "    print(\"~~~~~~~~~~~~~~~~~~~~~~[CONFUSION MATRIX:]~~~~~~~~~~~~~~~~~~~~~~~\" )\n",
    "    print(\"                 ......///\",comx[0], \"\\\\\\.........\" )\n",
    "    print(\"                 ...../// \",comx[1], \" \\\\\\.........\" )\n",
    "    #classification report\n",
    "    clr = classification_report(y_test,pred,output_dict=True)\n",
    "    clrdf = pd.DataFrame(clr)\n",
    "    #indic['true_positive']=clr['True']['precision']\n",
    "    #indic['true_negitive']=clr['False']['precision']\n",
    "    #indic['weighted avg'] =clr['weighted avg']['precision']\n",
    "    #indic['f1_score']     =clr['weighted avg']['f1-score']\n",
    "    modeldic[modelid] = indic\n",
    "    return [tree, modelid, pred,clrdf] #,codf.T#.iplot(kind='bar',theme='#solar')\n",
    "\n",
    "def forest_fit(x,y,dy,name=' ',notes=''):\n",
    "    indic = {}\n",
    "    mstamp = str(datetime.now())\n",
    "    '''model'''\n",
    "    mtype = 'forest'\n",
    "    sn = mstamp.split('.')[1]\n",
    "    modelid = mtype+sn\n",
    "    #adding paramaters\n",
    "    indic['model_id'] = modelid\n",
    "    indic['model_name'] = target+modelid #this is striclty beinf used for nameing\n",
    "    indic['model_notes'] =  'running 200 estimators'#notes\n",
    "    indic['stamp'] = mstamp\n",
    "    indic['model_type'] = mtype\n",
    "    indic['features'] = str(x.columns)\n",
    "    indic['target']   = target\n",
    "    #setting up model\n",
    "    '''object name'''\n",
    "    forest = RandomForestClassifier(200,'entropy')\n",
    "    forest.fit(x_train,y_train)\n",
    "    pred = forest.predict(x_test)\n",
    "    #metrics\n",
    "    clr = classification_report(y_test,pred)\n",
    "    dclr= classification_report(dy_test,pred)\n",
    "    print('~~~~~~~~~~~~~~~~~~~~~~~HITTNG THE TARGET~~~~~~~~~~~~~~~~~~~~~~~~~\\n',clr)\n",
    "    print('..............................vs................................')\n",
    "    print('~~~~~~~~~~~~~~~~~~~~~~~ THE ANTI-TARGET~~~~~~~~~~~~~~~~~~~~~~~~~\\n',dclr)\n",
    "    comx = confusion_matrix(y_test,pred)\n",
    "    print(\"~~~~~~~~~~~~~~~~~~~~~~[CONFUSION MATRIX:]~~~~~~~~~~~~~~~~~~~~~~~\" )\n",
    "    print(\"                 ......///\",comx[0], \"\\\\\\.........\" )\n",
    "    print(\"                 ...../// \",comx[1], \" \\\\\\.........\" )\n",
    "    #classification report\n",
    "    clr = classification_report(y_test,pred,output_dict=True)\n",
    "    clrdf = pd.DataFrame(clr)\n",
    "    indic['true_positive']=clr['True']['precision']\n",
    "    indic['true_negitive']=clr['False']['precision']\n",
    "    indic['weighted avg'] =clr['weighted avg']['precision']\n",
    "    indic['f1_score']     =clr['weighted avg']['f1-score']\n",
    "    modeldic[modelid] = indic\n",
    "    return [forest, modelid, pred,clrdf] #,codf.T#.iplot(kind='bar',theme='#solar')\n",
    "\n",
    "\n",
    "def lin_validate(lm,x):\n",
    "    pred = lm[0].predict(x)\n",
    "    predf[lm[1]] = pred\n",
    "    redf = predf[['Close',lm[1]]]\n",
    "    redf['time'] = ddf['Date']\n",
    "    redf.set_index('time',inplace=True)\n",
    "    r2 = r2_score(y,pred)\n",
    "    mae = mean_absolute_error(y,pred)\n",
    "    modeldic[lm[1]]['r2_score'] = r2\n",
    "    modeldic[lm[1]]['MAE'] = mae\n",
    "    #modeldic[lm[1]]['target'] = ltarget\n",
    "    print('r2 score',r2)\n",
    "    print('mean_absolute_er',mae)\n",
    "    #codf\n",
    "    #modeldic[lm[1]]['coefs'] = codf.T['coefs'].values\n",
    "    #modeldic[lm[1]] = indic\n",
    "    #sola(redf)\n",
    "    #sns.jointplot(pred,df_second[ltarget])\n",
    "\n",
    "def binary_validate(mdl,x):\n",
    "    pred = mdl[0].predict(x)\n",
    "    predf[mdl[1]] = pred\n",
    "    redf = predf[[target,'Close',mdl[1]]]\n",
    "    redf['time'] = ddf['Date']\n",
    "    redf.set_index('time',inplace=True)\n",
    "    sdf = scale(redf)\n",
    "    sdf['time'] = ddf['Date']\n",
    "    sdf.set_index('time',inplace=True)\n",
    "    #metrics\n",
    "    clr = classification_report(y,pred)\n",
    "    dclr= classification_report(dy_test,pred)\n",
    "    print('~~~~~~~~~~~~~~~~~~~~~~~HITTNG THE TARGET~~~~~~~~~~~~~~~~~~~~~~~~~\\n',clr)\n",
    "    print('..............................vs................................')\n",
    "    print('~~~~~~~~~~~~~~~~~~~~~~~ THE ANTI-TARGET~~~~~~~~~~~~~~~~~~~~~~~~~\\n',dclr)\n",
    "    comx = confusion_matrix(y,pred)\n",
    "    print(\"~~~~~~~~~~~~~~~~~~~~~~[CONFUSION MATRIX:]~~~~~~~~~~~~~~~~~~~~~~~\" )\n",
    "    print(\"                 ......///\",comx[0], \"\\\\\\.........\" )\n",
    "    print(\"                 ...../// \",comx[1], \" \\\\\\.........\" )\n",
    "    #the real price plot\n",
    "    scale2close= mdl[1]+'$scale'\n",
    "    redf[scale2close] = redf[mdl[1]].replace(True,1)\n",
    "    redf[scale2close] = redf[scale2close].replace(1,redf['Close'])\n",
    "    #sola(redf[['Close',scale2close]])\n",
    "    #scaled close\n",
    "    #sola(sdf.drop(target,1))\n",
    "    #scaled bionary\n",
    "    #sola(sdf[[target,mdl[1]]])\n",
    "    clr = classification_report(y,pred,output_dict=True)\n",
    "    clrdf = pd.DataFrame(clr)\n",
    "    modeldic[mdl[1]]['true_positive']=clr['True']['precision']\n",
    "    modeldic[mdl[1]]['true_negitive']=clr['False']['precision']\n",
    "    modeldic[mdl[1]]['weighted avg'] =clr['weighted avg']['precision']\n",
    "    modeldic[mdl[1]]['f1_score']     =clr['weighted avg']['f1-score']\n",
    "    modeldic[mdl[1]]['f1_score']\n",
    "    #modeldic[mdl[1]] = dic\n",
    "    return redf,pred\n",
    "\n",
    "\n",
    "\n",
    " \n",
    "    \n",
    "def scale(df):\n",
    "    '''returns your data frame scaled!'''\n",
    "    scale = StandardScaler()\n",
    "    scaled = scale.fit_transform(df)\n",
    "    sdf = pd.DataFrame(scaled,columns=df.columns)\n",
    "    return sdf\n",
    "\n",
    "\n",
    "'''\n",
    "def #sola(df):\n",
    "    return df#.iplot(theme='#solar',fill=True)\n",
    "'''\n",
    "\n",
    "def mix_info(modeldic,info):\n",
    "    #takes the model dict and ouputs dataFrame\n",
    "    # with the global data from 'info' dict\n",
    "    modf = pd.DataFrame(modeldic)\n",
    "    modf = modf.T\n",
    "    for i in info.keys():\n",
    "        modf[i] = info[i]\n",
    "    modf = modf.T    \n",
    "    modf.index.name = 'index'\n",
    "    return modf\n",
    "\n",
    "def save_info(csvname='model_preformance'):\n",
    "    cname = (csvname+'.csv')\n",
    "    info_path = 'PREDICTION_DATA/'\n",
    "    if not os.path.exists(info_path):\n",
    "        os.mkdir(info_path.replace('/',''))\n",
    "    yn = 'y'#input('do you want to save these results y/n?')\n",
    "    if yn == 'y':\n",
    "        yyn = 'loopy'#input('is there anything you want to add?')\n",
    "        if yyn == 'n':\n",
    "            pass\n",
    "        else:\n",
    "            #add_stuff = input('type some')\n",
    "            add_some = yyn\n",
    "            info['after_thoughts'] = add_some\n",
    "            info['sheet']          = sheet\n",
    "        #forming the dataframe\n",
    "        modf = mix_info(modeldic,info)\n",
    "        if cname in os.listdir(info_path):\n",
    "            print('its here ill update it')\n",
    "            mpdf = pd.read_csv(info_path+cname,index_col='index')\n",
    "            for i in modf.columns:\n",
    "                mpdf[i] = modf[i]\n",
    "                mpdf.to_csv(info_path+cname)\n",
    "            #modf.to_csv(info_path+cname)\n",
    "            print('cool i saved it!')\n",
    "        else:\n",
    "            print('its not there...')\n",
    "            modf.to_csv(info_path+cname)#,index_label='index')\n",
    "            print('..................now it is motha fucka!')\n",
    "            \n",
    "\n",
    "\n",
    "'''splits the date to a train/testset,validateset'''\n",
    "def df_splitt(split):\n",
    "    first = df[:split]\n",
    "    second = df[split:]\n",
    "    return first , second\n",
    "\n",
    "'''get rid of anything that leaks data of the future, marked by an exlamtion mark '''\n",
    "def lose_giveaways(df):\n",
    "    gaways = []\n",
    "    for i in df.columns:\n",
    "        if '!' in i:\n",
    "            gaways.append(i)\n",
    "    return df.drop(gaways,axis = 1)\n",
    "\n",
    "pd.set_option('display.max_columns',500)\n",
    "pd.set_option('display.max_rows',10000)\n",
    "\n",
    "#highlight de boo-LEANS!\n",
    "def hl(df):\n",
    "    def highlight(boo):\n",
    "        criteria = boo == True\n",
    "        return['background-color: green'if i else '' for i in criteria]\n",
    "    df = df.style.apply(highlight)\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# [[[[{{{{{{{{{{{ MACHINE LEARNING ZONE! }}}}}}}}}}]]]\n",
    "\n",
    "##### .................. ////////////////////////////////////////SPLIT\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\...............\n",
    "\n",
    "## <<<<<<<<<<<<<<<<<<< `LINEAR MODEL` >>>>>>>>>>>>>>>>>>>>>\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_squared_error,mean_absolute_error\n",
    "\n",
    "df.columns\n",
    "\n",
    "#CREATING LIST OF TARGETS!\n",
    "targs = []\n",
    "for i in df.columns:\n",
    "    if '!' in i:\n",
    "        targs.append(i)\n",
    "tardf = pd.DataFrame(targs,columns=['targets'])\n",
    "tardf\n",
    "\n",
    "# ---------------{define your TARGET!}--------------------\n",
    "\n",
    "ltarget = targs[6]\n",
    "ltarget\n",
    "\n",
    "fe_first = fe_first.rename(columns={'time':'date'})\n",
    "\n",
    "\n",
    "#SEPERATE FEATURES FROM TARGET\n",
    "\n",
    "x = fe_first.drop('date',axis=1)\n",
    "lx = x\n",
    "y = df_first[ltarget]\n",
    "#saving features to the thing\n",
    "#info['target'] = df[target]\n",
    "\n",
    "x_train,x_test,y_train,y_test = ttsplit(lx,y) #train_test_split simply saves some trouble, of typeing\n",
    "\n",
    "#ouputs the model, model_id, predictions and coeficiant dataframe in a list, while saving all parmas to 'modeldic'\n",
    "lm = lin_reg_fit(lx,y,notes='this is test 4')\n",
    "\n",
    "lm[3].T\n",
    "\n",
    "coedf = lm[3].T\n",
    "\n",
    "coedf.sort_values('coefs',ascending=False)\n",
    "\n",
    "\n",
    "\n",
    "# lets build a log reg model function ...\n",
    "\n",
    "import tqdm\n",
    "help(tqdm)\n",
    "\n",
    "tardf\n",
    "\n",
    "tarli = [8,9,10,11,12,13,22,23,24,25,26,27]\n",
    "#tarli = [26,27,22,23,24,25,34,35,11,10,9,12,8,13]\n",
    "for ml_target in tarli:\n",
    "    print(df[targs[ml_target]].name)\n",
    "    \n",
    "\n",
    "\n",
    "for ml_target in tarli:\n",
    "    try:\n",
    "        target  = targs[ml_target]\n",
    "\n",
    "        if 'up' in target:\n",
    "            dtarget = target.replace('up','down')\n",
    "        elif 'down' in target:\n",
    "            dtarget = target.replace('down','up')\n",
    "\n",
    "        elif 'above' in target:\n",
    "            dtarget = target.replace('above','below')\n",
    "        elif 'below' in target:\n",
    "            dtarget = target.replace('below','above')\n",
    "        print('target',target, '-->',dtarget)\n",
    "\n",
    "\n",
    "        #dtarget = targs[13]\n",
    "\n",
    "        print('target:     ',target, '\\nanti-target:',dtarget)\n",
    "\n",
    "        info['target'] = df[target]\n",
    "\n",
    "        ## <<<<<<<<<<<<<<<<< `LOGISTIC MODEL` >>>>>>>>>>>>>>>>>>>>\n",
    "        from sklearn.linear_model import LogisticRegression\n",
    "        from sklearn.metrics import classification_report, confusion_matrix,r2_score\n",
    "\n",
    "        ### -------------------------------({bionary} target selection)----------------------------------\n",
    "\n",
    "        ##sns.heatmap(df.isnull())\n",
    "\n",
    "        # ==============this is where i need to add d target to one log_reg_fit!\n",
    "\n",
    "\n",
    "        x = fe_first\n",
    "        x = x.drop(['date'],axis=1)\n",
    "        #x = scale(x)\n",
    "        y = df_first[target]\n",
    "        dy = df_first[dtarget]\n",
    "\n",
    "\n",
    "\n",
    "        x_train,x_test,y_train,y_test = ttsplit(x,y)\n",
    "        dx_train,dx_test,dy_train,dy_test = ttsplit(x,dy)\n",
    "\n",
    "\n",
    "\n",
    "        x\n",
    "\n",
    "        def log_reg_fit(x,y,dy,name=' ',notes=''):\n",
    "            #ouputs the model, model_id, predictions & coef_df in a list, while saving all parmas to 'modeldic'\n",
    "            #runs a Logistic model and save the paramaters, outputs,\n",
    "            #the model,model_id, prediction, and a coeficiant dataframe \n",
    "\n",
    "            indic = {}\n",
    "            mstamp = str(datetime.now())\n",
    "            '''model'''\n",
    "            mtype = 'LogisticRegression'\n",
    "            sn = mstamp.split('.')[1]\n",
    "            modelid = mtype+sn\n",
    "            #adding paramaters\n",
    "            indic['model_id'] = modelid\n",
    "            indic['model_name'] = target+modelid #this is striclty beinf used for nameing\n",
    "            indic['model_notes'] = 'max_iter is on 4000'#notes\n",
    "            indic['stamp'] = mstamp\n",
    "            indic['model_type'] = mtype\n",
    "            indic['features'] = str(x.columns)\n",
    "            indic['target']   = target\n",
    "            #setting up model\n",
    "            '''object name'''\n",
    "            lr = LogisticRegression(max_iter=4000)\n",
    "            lr.fit(x_train,y_train)\n",
    "            pred = lr.predict(x_test)\n",
    "            #dont think this will work on \n",
    "            coef = lr.coef_ \n",
    "\n",
    "            codf = pd.DataFrame(coef,columns=[x.columns])#,x.columns)#,columns=['coefs'])\n",
    "            #this would be if you wanted to rank them ....\n",
    "            #for i in trange(0,len(codf)):\n",
    "            #    if codf['coefs'][i] < 0:\n",
    "            #        codf['coefs'][i] = codf['coefs'][i] * -1\n",
    "            #codf = codf.T\n",
    "\n",
    "            codf#.iplot(kind='bar',theme='#solar')\n",
    "\n",
    "            #metrics\n",
    "            clr = classification_report(y_test,pred)\n",
    "            dclr= classification_report(dy_test,pred)\n",
    "            '''\n",
    "            print('~~~~~~~~~~~~~~~~~~~~~~~HITTNG THE TARGET~~~~~~~~~~~~~~~~~~~~~~~~~\\n',clr)\n",
    "            print('..............................vs................................')\n",
    "            print('~~~~~~~~~~~~~~~~~~~~~~~ THE ANTI-TARGET~~~~~~~~~~~~~~~~~~~~~~~~~\\n',dclr)\n",
    "            comx = confusion_matrix(y_test,pred)\n",
    "            print(\"~~~~~~~~~~~~~~~~~~~~~~[CONFUSION MATRIX:]~~~~~~~~~~~~~~~~~~~~~~~\" )\n",
    "            print(\"                 ......///\",comx[0], \"\\\\\\.........\" )\n",
    "            print(\"                 ...../// \",comx[1], \" \\\\\\.........\" )\n",
    "            '''\n",
    "            #classification report\n",
    "            clr = classification_report(y_test,pred,output_dict=True)\n",
    "            clrdf = pd.DataFrame(clr)\n",
    "            indic['true_positive']=clr['True']['precision']\n",
    "            indic['true_negitive']=clr['False']['precision']\n",
    "            indic['weighted avg'] =clr['weighted avg']['precision']\n",
    "            indic['f1_score']     =clr['weighted avg']['f1-score']\n",
    "            codf\n",
    "            modeldic[modelid] = indic\n",
    "            return [lr, modelid, pred,clrdf,codf] #,codf.T#.iplot(kind='bar',theme='#solar')\n",
    "\n",
    "\n",
    "        lr = log_reg_fit(x_train,y_train,dy_train)\n",
    "\n",
    "\n",
    "        lr[4].T.reset_index().sort_values(0,ascending=False)\n",
    "\n",
    "\n",
    "\n",
    "        os.listdir()\n",
    "\n",
    "        def save_log_coefs():\n",
    "            name = lr[1]\n",
    "            coefs = lr[4]\n",
    "            codf = coefs.T\n",
    "            codf = codf.reset_index().rename(columns={'level_0':'features',0:'coef'})\n",
    "            codf['true_coef'] = codf['coef']\n",
    "            for i in trange(0,len(codf)):\n",
    "                if codf['coef'][i] < 0:\n",
    "                    codf['coef'][i] = codf['coef'][i] * -1\n",
    "            p = 'PREDICTION_DATA/'\n",
    "            if not os.path.exists(p):\n",
    "                os.mkdir(p)\n",
    "            csname = ('coefs_'+target+'_split:'+str(split)+'.csv')\n",
    "            codf.to_csv(p+csname)\n",
    "            return codf.sort_values('coef',ascending=False)\n",
    "        save_log_coefs()\n",
    "\n",
    "\n",
    "\n",
    "        # Saving the Coefs Sheet\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # SWEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEET\n",
    "        ## .............................................TODO\n",
    "\n",
    "        ### OK THIS IS THE TEMPLATE TO APPLY TO THE REST OF THE BIONARY MODELS\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        lr[3]\n",
    "\n",
    "        ## <<<<<<<<<<<<<<<<<<<<<<< `TREE` >>>>>>>>>>>>>>>>>>>>>>>>>>\n",
    "\n",
    "        from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "        tree = tree_fit(x,y,dy_train)\n",
    "\n",
    "        tree\n",
    "\n",
    "        tree[3]\n",
    "\n",
    "        from sklearn.tree import plot_tree\n",
    "\n",
    "        plt.figure(figsize=(20,10))\n",
    "        plot_tree(tree[0],filled=True,max_depth=5)\n",
    "        plt.show()\n",
    "\n",
    "        lr[4].T.reset_index()\n",
    "\n",
    "        ## <<<<<<<<<<<<<<<<<<<< `FOREST` >>>>>>>>>>>>>>>>>>>>>>>\n",
    "\n",
    "        from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "\n",
    "        forest = forest_fit(x,y_train,dy_train)\n",
    "\n",
    "        forest[3]\n",
    "\n",
    "        modf = pd.DataFrame(modeldic)\n",
    "        modf\n",
    "\n",
    "        #     [[[[[[[[{{{{{{{{{{{ ~VALIDATE~ ! }}}}}}}}}}]]]]]]]]]]]\n",
    "\n",
    "        os.listdir(path)\n",
    "\n",
    "        ddf['Date'] = ddf['date']\n",
    "        #predf = second.copy()\n",
    "        df.head()\n",
    "\n",
    "        ### LIN TARGET\n",
    "\n",
    "        x = fe_second[lx.columns]\n",
    "        y = df_second[ltarget]\n",
    "\n",
    "\n",
    "        #sola(x)\n",
    "\n",
    "        ## <<<<<<<<<<<<<<<<<<<< `LINEAR` >>>>>>>>>>>>>>>>>>>>>>>\n",
    "\n",
    "        predf = df_second[['Close',target]] \n",
    "        lmp = lin_validate(lm,x)\n",
    "\n",
    "\n",
    "\n",
    "        ## <<<<<<<<<<<<<<<<<<<< `LOGISTIC` >>>>>>>>>>>>>>>>>>>>>>>\n",
    "\n",
    "        ### BIONARY TARGET\n",
    "\n",
    "        ### TODO\n",
    "        #### #add the date to result data frame\n",
    "        #### #add a plot of price to scale on the real close price\n",
    "        #### >add classification report with oposite values\n",
    "        #### # save metrics to dict...\n",
    "        ####  #true metrics vs pred plot,(just bionarys )\n",
    "        #### > add title & save image params to #sola function  \n",
    "        #### > add a prediction only function\n",
    "\n",
    "\n",
    "        def binary_validate(mdl,x,dy):\n",
    "            pred = mdl[0].predict(x)\n",
    "            predf[mdl[1]] = pred\n",
    "            redf = predf[[target,'Close',mdl[1]]]\n",
    "            redf['time'] = ddf['Date']\n",
    "            redf.set_index('time',inplace=True)\n",
    "            sdf = scale(redf)\n",
    "            sdf['time'] = ddf['Date']\n",
    "            sdf.set_index('time',inplace=True)\n",
    "            #metrics\n",
    "            clr = classification_report(y,pred)\n",
    "            dclr= classification_report(dy,pred)\n",
    "            '''\n",
    "            print('~~~~~~~~~~~~~~~~~~~~~~~HITTNG THE TARGET~~~~~~~~~~~~~~~~~~~~~~~~~\\n',clr)\n",
    "            print('..............................vs................................')\n",
    "            print('~~~~~~~~~~~~~~~~~~~~~~~ THE ANTI-TARGET~~~~~~~~~~~~~~~~~~~~~~~~~\\n',dclr)\n",
    "            comx = confusion_matrix(y,pred)\n",
    "            print(\"~~~~~~~~~~~~~~~~~~~~~~[CONFUSION MATRIX:]~~~~~~~~~~~~~~~~~~~~~~~\" )\n",
    "            print(\"                 ......///\",comx[0], \"\\\\\\.........\" )\n",
    "            print(\"                 ...../// \",comx[1], \" \\\\\\.........\" )\n",
    "            '''\n",
    "            #the real price plot\n",
    "            scale2close= mdl[1]+'_$scale'\n",
    "            redf[scale2close] = redf[mdl[1]].replace(True,1)\n",
    "            redf[scale2close] = redf[scale2close].replace(1,redf['Close'])\n",
    "            print(sdf[target].name)\n",
    "            #sola(redf[['Close',scale2close]])\n",
    "            #scaled close\n",
    "            ##sola(sdf.drop(target,1))\n",
    "            #scaled bionary\n",
    "            ##sola(sdf[[target,mdl[1]]])\n",
    "            clr = classification_report(y,pred,output_dict=True)\n",
    "            clrdf = pd.DataFrame(clr)\n",
    "            dclr = classification_report(dy,pred,output_dict=True)\n",
    "            dclrdf = pd.DataFrame(dclr)\n",
    "            modeldic[mdl[1]]['target']      = target\n",
    "            modeldic[mdl[1]]['true_positive']=clr['True']['precision']\n",
    "            modeldic[mdl[1]]['true_negitive']=clr['False']['precision']\n",
    "            modeldic[mdl[1]]['weighted avg'] =clr['weighted avg']['precision']\n",
    "            modeldic[mdl[1]]['f1_score']     =clr['weighted avg']['f1-score']\n",
    "            modeldic[mdl[1]]['dtrue_positive']=dclr['True']['precision']\n",
    "            modeldic[mdl[1]]['dtrue_negitive']=dclr['False']['precision']\n",
    "            modeldic[mdl[1]]['dweighted avg'] =dclr['weighted avg']['precision']\n",
    "            modeldic[mdl[1]]['df1_score']     =dclr['weighted avg']['f1-score']\n",
    "            modeldic[mdl[1]]['true_dtrue_dif']=clr['True']['precision'] - dclr['True']['precision']\n",
    "            modeldic[mdl[1]]['wt_dwt_avg_dif'] =clr['weighted avg']['precision']-dclr['weighted avg']['precision']\n",
    "            modeldic[mdl[1]]['f1_score']\n",
    "            #modeldic[mdl[1]] = dic\n",
    "            return redf,pred\n",
    "\n",
    "\n",
    "\n",
    "        print(len(fe_second),len(df_second))\n",
    "\n",
    "        print(len(df_second[target]))\n",
    "        print(len(fe_second))\n",
    "\n",
    "        x = fe_second\n",
    "        x = x.drop(['date'],axis=1)\n",
    "        y = df_second[target]#.replace(1,True).replace(0,False)\n",
    "        dy = df_second[dtarget]#.replace(1,True).replace(0,False)\n",
    "        x.head()\n",
    "\n",
    "\n",
    "\n",
    "        lrp = binary_validate(lr,x,dy)\n",
    "\n",
    "\n",
    "        # Predf is a dataframe ofall the predictions?\n",
    "\n",
    "        predf\n",
    "\n",
    "\n",
    "\n",
    "        ## <<<<<<<<<<<<<<<<<<<< `TREE` >>>>>>>>>>>>>>>>>>>>>>>\n",
    "\n",
    "        treep = binary_validate(tree,x,dy)\n",
    "\n",
    "        redf = treep[0]\n",
    "        redf[dtarget] = df[dtarget]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        ## <<<<<<<<<<<<<<<<<<<< `FOREST` >>>>>>>>>>>>>>>>>>>>>>>\n",
    "\n",
    "        forestp = binary_validate(forest,x,dy) \n",
    "\n",
    "        forestp[0]\n",
    "\n",
    "        pd.DataFrame(modeldic)\n",
    "\n",
    "\n",
    "\n",
    "        modf = pd.DataFrame(modeldic)\n",
    "\n",
    "        ## try adding more bars here\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "        # [[[[[[[[{{{{{{{{{{{ SAVE RESULTS ZONE! }}}}}}}}}}]]]]]]]]]]]\n",
    "\n",
    "        \n",
    "         ### save predictions\n",
    "\n",
    "        predf['date'] = df['date']\n",
    "\n",
    "        pppath = 'PREDICTION_DATA/predictions/'\n",
    "        if not os.path.exists(pppath):\n",
    "            os.mkdir(pppath)\n",
    "        pppname = (pppath+target+'_split:'+str(split)+'.csv')\n",
    "        predf.to_csv(pppname)\n",
    "\n",
    "\n",
    "        fin = 'fin:'+str(datetime.now()) \n",
    "\n",
    "        \n",
    "        \n",
    "        fin = 'fin:'+str(datetime.now()) \n",
    "\n",
    "        import pickle\n",
    "\n",
    "        \n",
    "\n",
    "        def pickle_suprise(model):\n",
    "            # save the model to disk\n",
    "            modell = model[0]\n",
    "            pickle_path = ('pickles/')\n",
    "            if not os.path.exists(pickle_path):\n",
    "                os.mkdir(pickle_path)\n",
    "            filename = (pickle_path+model[1])\n",
    "            pickle.dump(modell, open(filename, 'wb'))\n",
    "\n",
    "            # some time later...\n",
    "\n",
    "            # load the model from disk\n",
    "            #loaded_model = pickle.load(open(filename, 'rb'))\n",
    "            #result = loaded_model.score(x_test, y_test)\n",
    "            #print(result)\n",
    "            #print(filename)\n",
    "\n",
    "        save_info()\n",
    "        #eventually these should go into the save_info function, but this works nive ads a hard stop\n",
    "        pickle_suprise(lm)\n",
    "        pickle_suprise(lr)\n",
    "        pickle_suprise(tree)\n",
    "        pickle_suprise(forest)\n",
    "    \n",
    "    except IndexError:\n",
    "        pass\n",
    "    except KeyError:\n",
    "        pass\n",
    "    except ValueError:\n",
    "        pass\n",
    "    \n",
    "\n",
    "# Common Errors\n",
    "\n",
    "#except IndexError:\n",
    "    #   pass\n",
    "    #except KeyError:\n",
    "    #    pass\n",
    "    #except ValueError:\n",
    "    #    pass\n",
    "    \n",
    "\n",
    "modf.T[['true_dtrue_dif','wt_dwt_avg_dif']]#.iplot(kind='bar',theme='#solar')\n",
    "\n",
    "modeldic[lm[1]].keys()\n",
    "\n",
    "clean_compleate = datetime.now()\n",
    "notebook_runtime = clean_compleate - clean_initiate\n",
    "print('notebook ran in: ',notebook_runtime)\n",
    "\n",
    "\n",
    "mpdf = pd.read_csv('PREDICTION_DATA/model_preformance.csv',index_col='index')\n",
    "mpdf.T[['true_dtrue_dif','wt_dwt_avg_dif']]#.iplot(theme='#solar',fill=True)\n",
    "mpdf.T[['true_dtrue_dif','wt_dwt_avg_dif']]#.iplot(theme='#solar',kind='bar')\n",
    "mpdf.T[['true_positive','weighted avg','true_negitive','f1_score']]#.iplot(theme='#solar',kind='bar')\n",
    "\n",
    "# you have to add notes or it wont save csv_name\n",
    "### odly enough true_negitive is more important than true negitive...makes sence\n",
    "\n",
    "mpdf\n",
    "\n",
    "#!>models.md\n",
    "stamp\n",
    "\n",
    "\n",
    "print('notebook runtime:\\n'\n",
    "      ,str(datetime.now() -pd.to_datetime(stamp)).split(' ')[2].split('.')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
